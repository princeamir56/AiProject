================================================================================
RAPPORT DE COMPARAISON DES MOD√àLES DE MACHINE LEARNING
================================================================================

MOD√àLES IMPL√âMENT√âS
----------------------------------------

1. GRADIENT BOOSTING REGRESSOR
   Famille: Ensemble Learning (Boosting)
   Hyperparam√®tres:
     - n_estimators: 200
     - max_depth: 5
     - learning_rate: 0.1
   Justification: M√©thode d'ensemble qui construit s√©quentiellement
   des arbres de d√©cision, chacun corrigeant les erreurs du pr√©c√©dent.
   Excellent pour capturer les relations non-lin√©aires complexes.

2. RANDOM FOREST REGRESSOR
   Famille: Ensemble Learning (Bagging)
   Hyperparam√®tres:
     - n_estimators: 200
     - max_depth: 15
     - max_features: sqrt
   Justification: Agr√®ge les pr√©dictions de multiples arbres ind√©pendants.
   Robuste aux outliers et fournit une mesure d'importance des features.

3. RIDGE REGRESSION
   Famille: R√©gression lin√©aire r√©gularis√©e (L2)
   Hyperparam√®tres:
     - alpha: 10
   Justification: Mod√®le lin√©aire simple avec r√©gularisation L2.
   G√®re bien la multicolin√©arit√© et sert de baseline interpr√©table.


R√âSULTATS
----------------------------------------

GradientBoosting:
  - Test RMSE: $22,308
  - Test R¬≤: 0.9099
  - CV RMSE: $27,354 (¬±$4,295)

RandomForest:
  - Test RMSE: $25,134
  - Test R¬≤: 0.8856
  - CV RMSE: $29,555 (¬±$4,222)

Ridge:
  - Test RMSE: $26,686
  - Test R¬≤: 0.8711
  - CV RMSE: $28,817 (¬±$2,807)


üèÜ MEILLEUR MOD√àLE RETENU: GradientBoosting
----------------------------------------
Ce mod√®le a √©t√© s√©lectionn√© car il pr√©sente:
  - Le meilleur RMSE sur les donn√©es de test
  - Un bon score R¬≤ (0.9099)
  - Une bonne g√©n√©ralisation (faible overfitting)
