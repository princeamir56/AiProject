{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d4e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_validate, learning_curve, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Add project root\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "from ml.preprocessing import (\n",
    "    create_preprocessing_pipeline,\n",
    "    prepare_data,\n",
    "    get_numeric_features,\n",
    "    get_categorical_features\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Paths\n",
    "DATA_PATH = Path('../data/train.csv')\n",
    "MODELS_DIR = Path('../ml/models')\n",
    "FIGURES_DIR = Path('../report/figures')\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e51922",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed3b5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Prepare features and target\n",
    "X, y = prepare_data(df, target_col='SalePrice', log_transform_target=True)\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Target (log1p) - Min: {y.min():.2f}, Max: {y.max():.2f}, Mean: {y.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5519d5b",
   "metadata": {},
   "source": [
    "## 2. Define Models and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6aa527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preprocessing pipeline\n",
    "preprocessor = create_preprocessing_pipeline(scale_numeric=True)\n",
    "\n",
    "# Define 3 models\n",
    "models = {\n",
    "    'Ridge': Ridge(alpha=10.0),\n",
    "    'RandomForest': RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=2,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'HistGradientBoosting': HistGradientBoostingRegressor(\n",
    "        max_iter=200,\n",
    "        max_depth=10,\n",
    "        learning_rate=0.1,\n",
    "        min_samples_leaf=20,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "print(f\"Models to compare: {list(models.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76027687",
   "metadata": {},
   "source": [
    "## 3. 5-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ae43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate each model with 5-fold CV\n",
    "results = {}\n",
    "pipelines = {}\n",
    "\n",
    "scoring = {\n",
    "    'neg_mse': 'neg_mean_squared_error',\n",
    "    'neg_mae': 'neg_mean_absolute_error',\n",
    "    'r2': 'r2'\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining: {name}\")\n",
    "    \n",
    "    # Create full pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    pipelines[name] = pipeline\n",
    "    \n",
    "    # 5-Fold CV\n",
    "    cv_results = cross_validate(\n",
    "        pipeline, X, y,\n",
    "        cv=5,\n",
    "        scoring=scoring,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(-cv_results['test_neg_mse'])\n",
    "    mae = -cv_results['test_neg_mae']\n",
    "    r2 = cv_results['test_r2']\n",
    "    \n",
    "    results[name] = {\n",
    "        'rmse_mean': rmse.mean(),\n",
    "        'rmse_std': rmse.std(),\n",
    "        'mae_mean': mae.mean(),\n",
    "        'mae_std': mae.std(),\n",
    "        'r2_mean': r2.mean(),\n",
    "        'r2_std': r2.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"  RMSE: {rmse.mean():.4f} ¬± {rmse.std():.4f}\")\n",
    "    print(f\"  MAE:  {mae.mean():.4f} ¬± {mae.std():.4f}\")\n",
    "    print(f\"  R¬≤:   {r2.mean():.4f} ¬± {r2.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80d9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results summary table\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(4)\n",
    "results_df['RMSE'] = results_df['rmse_mean'].astype(str) + ' ¬± ' + results_df['rmse_std'].astype(str)\n",
    "results_df['MAE'] = results_df['mae_mean'].astype(str) + ' ¬± ' + results_df['mae_std'].astype(str)\n",
    "results_df['R¬≤'] = results_df['r2_mean'].astype(str) + ' ¬± ' + results_df['r2_std'].astype(str)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"5-FOLD CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\"*60)\n",
    "results_df[['RMSE', 'MAE', 'R¬≤']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d34d5",
   "metadata": {},
   "source": [
    "## 4. CV Comparison Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5188afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CV comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "model_names = list(results.keys())\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.6\n",
    "colors = ['#3498db', '#2ecc71', '#e74c3c']\n",
    "\n",
    "# RMSE\n",
    "ax = axes[0]\n",
    "rmse_means = [results[m]['rmse_mean'] for m in model_names]\n",
    "rmse_stds = [results[m]['rmse_std'] for m in model_names]\n",
    "bars = ax.bar(x, rmse_means, width, yerr=rmse_stds, color=colors, capsize=5, alpha=0.8)\n",
    "ax.set_ylabel('RMSE (log scale)', fontsize=11)\n",
    "ax.set_title('RMSE Comparison (5-Fold CV)', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, fontsize=10)\n",
    "for bar, val in zip(bars, rmse_means):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "            f'{val:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# MAE\n",
    "ax = axes[1]\n",
    "mae_means = [results[m]['mae_mean'] for m in model_names]\n",
    "mae_stds = [results[m]['mae_std'] for m in model_names]\n",
    "bars = ax.bar(x, mae_means, width, yerr=mae_stds, color=colors, capsize=5, alpha=0.8)\n",
    "ax.set_ylabel('MAE (log scale)', fontsize=11)\n",
    "ax.set_title('MAE Comparison (5-Fold CV)', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, fontsize=10)\n",
    "for bar, val in zip(bars, mae_means):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.003,\n",
    "            f'{val:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# R2\n",
    "ax = axes[2]\n",
    "r2_means = [results[m]['r2_mean'] for m in model_names]\n",
    "r2_stds = [results[m]['r2_std'] for m in model_names]\n",
    "bars = ax.bar(x, r2_means, width, yerr=r2_stds, color=colors, capsize=5, alpha=0.8)\n",
    "ax.set_ylabel('R¬≤ Score', fontsize=11)\n",
    "ax.set_title('R¬≤ Comparison (5-Fold CV)', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(model_names, fontsize=10)\n",
    "ax.set_ylim(0, 1)\n",
    "for bar, val in zip(bars, r2_means):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{val:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'cv_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {FIGURES_DIR / 'cv_comparison.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4fbde1",
   "metadata": {},
   "source": [
    "## 5. Select Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38de28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select best model (lowest RMSE)\n",
    "best_model_name = min(results, key=lambda x: results[x]['rmse_mean'])\n",
    "best_pipeline = pipelines[best_model_name]\n",
    "best_results = results[best_model_name]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(f\"BEST MODEL: {best_model_name}\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"RMSE: {best_results['rmse_mean']:.4f} ¬± {best_results['rmse_std']:.4f}\")\n",
    "print(f\"MAE:  {best_results['mae_mean']:.4f} ¬± {best_results['mae_std']:.4f}\")\n",
    "print(f\"R¬≤:   {best_results['r2_mean']:.4f} ¬± {best_results['r2_std']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d342f02a",
   "metadata": {},
   "source": [
    "## 6. Train Best Model and Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4f3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit best model on full data\n",
    "best_pipeline.fit(X, y)\n",
    "y_pred = best_pipeline.predict(X)\n",
    "\n",
    "# Also get cross-validated predictions for unbiased evaluation\n",
    "y_pred_cv = cross_val_predict(best_pipeline, X, y, cv=5)\n",
    "\n",
    "print(f\"Training predictions: {len(y_pred)}\")\n",
    "print(f\"CV predictions: {len(y_pred_cv)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a023714",
   "metadata": {},
   "source": [
    "## 7. Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a657b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals using CV predictions (unbiased)\n",
    "residuals = y.values - y_pred_cv\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Residuals vs Predicted\n",
    "ax = axes[0]\n",
    "ax.scatter(y_pred_cv, residuals, alpha=0.5, s=30, c='#3498db')\n",
    "ax.axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Predicted Values (log scale)', fontsize=11)\n",
    "ax.set_ylabel('Residuals', fontsize=11)\n",
    "ax.set_title(f'{best_model_name}: Residuals vs Predicted (CV)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Residual distribution\n",
    "ax = axes[1]\n",
    "ax.hist(residuals, bins=50, edgecolor='white', color='#2ecc71', alpha=0.7)\n",
    "ax.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
    "ax.axvline(x=residuals.mean(), color='blue', linestyle='--', linewidth=2, \n",
    "           label=f'Mean: {residuals.mean():.4f}')\n",
    "ax.set_xlabel('Residuals', fontsize=11)\n",
    "ax.set_ylabel('Frequency', fontsize=11)\n",
    "ax.set_title(f'{best_model_name}: Residual Distribution', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'residuals.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {FIGURES_DIR / 'residuals.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62608dbe",
   "metadata": {},
   "source": [
    "## 8. Predicted vs Actual Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a404f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs Actual using CV predictions\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ax.scatter(y.values, y_pred_cv, alpha=0.5, s=30, c='#3498db')\n",
    "\n",
    "# Perfect prediction line\n",
    "min_val = min(y.min(), y_pred_cv.min())\n",
    "max_val = max(y.max(), y_pred_cv.max())\n",
    "ax.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "\n",
    "# Metrics\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "r2 = r2_score(y, y_pred_cv)\n",
    "\n",
    "ax.set_xlabel('Actual Values (log scale)', fontsize=11)\n",
    "ax.set_ylabel('Predicted Values (log scale)', fontsize=11)\n",
    "ax.set_title(f'{best_model_name}: Predicted vs Actual (CV)\\nRMSE={rmse:.4f}, R¬≤={r2:.4f}', \n",
    "             fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'predicted_vs_actual.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {FIGURES_DIR / 'predicted_vs_actual.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d80c32",
   "metadata": {},
   "source": [
    "## 9. Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922d8fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "train_sizes = np.linspace(0.1, 1.0, 10)\n",
    "\n",
    "train_sizes_abs, train_scores, test_scores = learning_curve(\n",
    "    best_pipeline, X, y,\n",
    "    train_sizes=train_sizes,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Convert to RMSE\n",
    "train_rmse = np.sqrt(-train_scores)\n",
    "test_rmse = np.sqrt(-test_scores)\n",
    "\n",
    "train_mean = train_rmse.mean(axis=1)\n",
    "train_std = train_rmse.std(axis=1)\n",
    "test_mean = test_rmse.mean(axis=1)\n",
    "test_std = test_rmse.std(axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.fill_between(train_sizes_abs, train_mean - train_std, train_mean + train_std, \n",
    "                alpha=0.2, color='#3498db')\n",
    "ax.fill_between(train_sizes_abs, test_mean - test_std, test_mean + test_std, \n",
    "                alpha=0.2, color='#e74c3c')\n",
    "\n",
    "ax.plot(train_sizes_abs, train_mean, 'o-', color='#3498db', linewidth=2, \n",
    "        label='Training Score')\n",
    "ax.plot(train_sizes_abs, test_mean, 'o-', color='#e74c3c', linewidth=2, \n",
    "        label='Validation Score')\n",
    "\n",
    "ax.set_xlabel('Training Set Size', fontsize=11)\n",
    "ax.set_ylabel('RMSE (log scale)', fontsize=11)\n",
    "ax.set_title(f'{best_model_name}: Learning Curve', fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'learning_curve.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(f\"Saved: {FIGURES_DIR / 'learning_curve.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da8986d",
   "metadata": {},
   "source": [
    "## 10. Save Best Pipeline & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4363e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best pipeline\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f\"best_pipeline_{timestamp}.joblib\"\n",
    "model_path = MODELS_DIR / model_filename\n",
    "\n",
    "joblib.dump(best_pipeline, model_path)\n",
    "print(f\"‚úì Model saved: {model_path}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics = {\n",
    "    'best_model': best_model_name,\n",
    "    'timestamp': timestamp,\n",
    "    'dataset': {\n",
    "        'instances': len(df),\n",
    "        'features': len(X.columns),\n",
    "        'numeric_features': get_numeric_features(),\n",
    "        'categorical_features': get_categorical_features()\n",
    "    },\n",
    "    'cv_results': {k: {kk: float(vv) for kk, vv in v.items()} for k, v in results.items()},\n",
    "    'best_model_metrics': {\n",
    "        'rmse': float(best_results['rmse_mean']),\n",
    "        'rmse_std': float(best_results['rmse_std']),\n",
    "        'mae': float(best_results['mae_mean']),\n",
    "        'mae_std': float(best_results['mae_std']),\n",
    "        'r2': float(best_results['r2_mean']),\n",
    "        'r2_std': float(best_results['r2_std'])\n",
    "    },\n",
    "    'model_path': str(model_path)\n",
    "}\n",
    "\n",
    "metrics_path = MODELS_DIR / \"metrics.json\"\n",
    "with open(metrics_path, 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(f\"‚úì Metrics saved: {metrics_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d7d610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n‚òÖ Best Model: {best_model_name}\")\n",
    "print(f\"  RMSE (CV): {best_results['rmse_mean']:.4f} ¬± {best_results['rmse_std']:.4f}\")\n",
    "print(f\"  MAE (CV):  {best_results['mae_mean']:.4f} ¬± {best_results['mae_std']:.4f}\")\n",
    "print(f\"  R¬≤ (CV):   {best_results['r2_mean']:.4f} ¬± {best_results['r2_std']:.4f}\")\n",
    "print(f\"\\nüìÅ Files saved:\")\n",
    "print(f\"  Model: {model_path}\")\n",
    "print(f\"  Metrics: {metrics_path}\")\n",
    "print(f\"  Figures: {FIGURES_DIR}\")\n",
    "print(\"\\nüìä All Model Results:\")\n",
    "for name, res in results.items():\n",
    "    marker = \"‚òÖ\" if name == best_model_name else \" \"\n",
    "    print(f\"  {marker} {name}: RMSE={res['rmse_mean']:.4f}, R¬≤={res['r2_mean']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
